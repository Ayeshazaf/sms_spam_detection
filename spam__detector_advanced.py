# -*- coding: utf-8 -*-
"""Spam _detector.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sc0cEo8P3JElycto8OLTOEub7_52jzXf
"""

import pandas as pd
import numpy as np
import re
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import LabelEncoder
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer
from transformers import (
    AutoTokenizer,
    AutoModel,
    AutoModelForSequenceClassification,
    Trainer,
    TrainingArguments,
    DataCollatorWithPadding,
)
from datasets import Dataset
import torch

def cleaning_data(text: str) -> str:
    text = text.lower()
    text = re.sub(r"http\S+|www\S+", " ", text)   # URLs
    text = re.sub(r"@\w+", " ", text)             # mentions
    text = re.sub(r"#(\w+)", r"\1", text)         # hashtags -> word
    text = re.sub(r"[^a-z\s$%0-9]", " ", text)    # keep letters, digits, $, %
    text = re.sub(r"\s+", " ", text).strip()
    return text

def load_data(path = "spamdata/spam_sms.csv"):
    df = pd.read_csv(path)
    df = df.rename(columns={"v1": "labels", "v2": "text"})
    df["CleanMessage"] = df["text"].astype(str).apply(cleaning_data)
    return df

def split_dataset(df):
    train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df["labels"])
    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df["labels"])
    return train_df, val_df, test_df

# TF-IDF Vectorizer and Model Training
def fit_tfidf_on_train(train_texts):
    vect = TfidfVectorizer(ngram_range=(1, 2), min_df=2)
    vect.fit(train_texts)
    return vect

# Transform texts using the fitted vectorizer
def transform_with_vect(vect: TfidfVectorizer, texts):
    return vect.transform(texts)

# Train Naive Bayes
def train_nb(X_train, y_train):
    naive_bayes = MultinomialNB().fit(X_train, y_train)
    return naive_bayes

# Training and Hyperparameter tuning for Logistic Regression
def tune_lr(X_train, y_train, X_val, y_val):
    # simple grid on C
    grid = {"C": [0.25, 0.5, 1.0, 2.0, 4.0]}
    lr = LogisticRegression(max_iter=500, class_weight="balanced")
    gs = GridSearchCV(lr, grid, scoring="f1_weighted", cv=3, n_jobs=-1)
    gs.fit(X_train, y_train)
    best = gs.best_estimator_
    val_f1 = f1_score(y_val, best.predict(X_val), average="weighted")
    return best, gs.best_params_, val_f1


# Evaluate model performance
def evaluate(model, X, y):
    pred = model.predict(X)
    return (
        accuracy_score(y, pred),
        precision_score(y, pred, average="weighted"),
        recall_score(y, pred, average="weighted"),
        f1_score(y, pred, average="weighted"),
    )


# Pipeline for logistic regression and naive bayes

def pipeline_lr_nb(train_df, val_df, test_df):
    vect = fit_tfidf_on_train(train_df["CleanMessage"])
    X_train = transform_with_vect(vect, train_df["CleanMessage"])
    X_val = transform_with_vect(vect, val_df["CleanMessage"])
    X_test = transform_with_vect(vect, test_df["CleanMessage"])

    y_train = train_df["labels"]
    y_val = val_df["labels"]
    y_test = test_df["labels"]

    nb_model = train_nb(X_train, y_train)
    lr_model, best_params, val_f1 = tune_lr(X_train, y_train, X_val, y_val)

    models = {
        "Naive Bayes": nb_model,
        "Logistic Regression": lr_model,
    }
    performances = {}
    for name, model in models.items():
        performances[name] = {
            "Train": evaluate(model, X_train, y_train),
            "Validation": evaluate(model, X_val, y_val),
            "Test": evaluate(model, X_test, y_test),
        }
    return vect, models, performances, best_params

def fine_tune_distilbert(train_texts, train_labels, val_texts, val_labels, num_labels):
    device = "cuda" if torch.cuda.is_available() else "cpu"

    model_name = "distilbert-base-uncased"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)
    model.to(device)

    train_encodings = tokenizer(train_texts, truncation=True, padding=True)
    val_encodings = tokenizer(val_texts, truncation=True, padding=True)

    train_dataset = Dataset.from_dict({**train_encodings, "labels": train_labels})
    val_dataset = Dataset.from_dict({**val_encodings, "labels": val_labels})
    tokenized_datasets = {"train": train_dataset, "validation": val_dataset}
    training_args = TrainingArguments(
        output_dir="test-trainer",
        num_train_epochs=3,
        per_device_train_batch_size=16,
        per_device_eval_batch_size=32
    )


    def compute_metrics(eval_pred):
        logits, labels = eval_pred
        preds = np.argmax(logits, axis=1)
        precision = precision_score(labels, preds, average="weighted")
        recall = recall_score(labels, preds, average="weighted")
        f1 = f1_score(labels, preds, average="weighted")
        acc = accuracy_score(labels, preds)
        return {"accuracy": acc, "precision": precision, "recall": recall, "f1": f1}

    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)


    trainer = Trainer(
        model,
        training_args,
        train_dataset=tokenized_datasets["train"],
        eval_dataset=tokenized_datasets["validation"],
        data_collator=data_collator,
        tokenizer=tokenizer,
        compute_metrics=compute_metrics
        )

    trainer.train()
    return tokenizer, model, trainer

# Predict with DistilBERT
def predict_distilbert(tokenizer, model, texts):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model.to(device)
    encodings = tokenizer(texts, truncation=True, padding=True, return_tensors="pt")
    encodings = {k: v.to(device) for k, v in encodings.items()}
    with torch.no_grad():
        outputs = model(**encodings)
    logits = outputs.logits
    preds = torch.argmax(logits, axis=1).cpu().numpy()
    return preds

df = load_data()
train_df, val_df, test_df = split_dataset(df)

# Train and evaluate Logistic Regression & Naive Bayes
vect, models, performances, best_params = pipeline_lr_nb(train_df, val_df, test_df)

# Prepare DistilBERT data
label_encoder = LabelEncoder()
train_labels = label_encoder.fit_transform(train_df["labels"])
val_labels = label_encoder.transform(val_df["labels"])
test_labels = label_encoder.transform(test_df["labels"])

# Fine-tune DistilBERT (this may take time)
tokenizer, bert_model, bert_trainer = fine_tune_distilbert(
    train_df["CleanMessage"].tolist(),
    train_labels.tolist(),
    val_df["CleanMessage"].tolist(),
    val_labels.tolist(),
    num_labels=len(label_encoder.classes_)
)

# Evaluate DistilBERT
bert_test_preds = predict_distilbert(tokenizer, bert_model, test_df["CleanMessage"].tolist())
bert_acc = accuracy_score(test_labels, bert_test_preds)
bert_prec = precision_score(test_labels, bert_test_preds, average="weighted")
bert_rec = recall_score(test_labels, bert_test_preds, average="weighted")
bert_f1 = f1_score(test_labels, bert_test_preds, average="weighted")

print("Logistic Regression:")
print("Test Accuracy:",f"{performances['Logistic Regression']['Test'][0]:.4f}")
print("Test Precision:",f"{performances['Logistic Regression']['Test'][1]:.4f}")
print("Test Recall:",f"{performances['Logistic Regression']['Test'][2]:.4f}")
print("Test F1 Score:",f"{performances['Logistic Regression']['Test'][3]:.4f}")
print("\nNaive Bayes:")
print("Test Accuracy:",f"{performances['Naive Bayes']['Test'][0]:.4f}")
print("Test Precision:",f"{performances['Naive Bayes']['Test'][1]:.4f}")
print("Test Recall:",f"{performances['Naive Bayes']['Test'][2]:.4f}")
print("Test F1 Score:",f"{performances['Naive Bayes']['Test'][3]:.4f}")
print("\nDistilBERT:")
print("Test Accuracy:", bert_acc)
print("Test Precision:", bert_prec)
print("Test Recall:", bert_rec)
print("Test F1 Score:", bert_f1)